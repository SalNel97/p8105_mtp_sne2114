---
title: "Data Science I (P8105) Midterm"
author: "Salah El-Sadek (sne2114)"
output: github_document
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(ggridges)
library(patchwork)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

### Problem 1

|      The dog weights dataset includes data on the weights of three pet dogs: Raisin, Simone, and Gagne. Weight was recorded for each pet in pounds and ounces along with the standard deviation for weight measurements and date the pets were weighed. Notes are also included on some dates to explain things such as missing data for any of the pets, for example. The goal is to analyze any trends or changes to each pet's weight as a way to keep track of any potential health issues.

|      Import and clean dog weights data set, skipping first header row and omitting notes column. The column type for the column 'date' was changed to numeric then into date format, since 'date' values in excel are custom (numerically coded) formats, not date formats.

```{r read and tidy}
weights_tidy = 
  read_excel(
    "./data/dogweights_07sept2020.xlsx", skip = 1) %>%
  janitor::clean_names() %>%
  select(-x6) %>%
  mutate(
    date = as.numeric(date),
    date = as.Date(date, origin = "1899-12-30"))

weights_tidy
```

|      Used pivot_longer to rearrange weight measurement per pet name. Also helps with not dropping rows with weight data missing from only 1 or 2 pets. Rows with improper dates were also omitted (one row). The weight column containing weight measurements was separated into lbs and oz, the oz values divided by 16 then summed with the lbs to give a total weight in pounds for each entry .Same was done to standard deviation column as well.

```{r pivot_longer and drop_na}
weights_tidy = 
  weights_tidy %>% 
  pivot_longer(
    raisin:gagne,
    names_to = "pet_name",
    values_to = "weight_lbs_oz") %>% 
  drop_na(weight_lbs_oz) %>% 
  separate(
    weight_lbs_oz,
    into = c("weight_lbs", "weight_oz"),
    sep = "\\s", extra = "merge") %>% 
  separate(
    std,
    into = c("std_lbs", "std_oz"),
    sep = "\\s", extra = "merge") %>% 
  mutate(
    weight_lbs = as.numeric(weight_lbs),
    std_lbs = as.numeric(std_lbs),
    weight_oz = as.numeric(weight_oz),
    std_oz = as.numeric(std_oz))

weights_tidy

weights_tidy =
  weights_tidy %>% 
  mutate(
    weight_oz = weight_oz / 16,
    std_oz = std_oz / 16,
    total_weight_lbs = weight_lbs + weight_oz,
    total_std_lbs = std_lbs + std_oz) %>% 
  select(date, pet_name, total_weight_lbs, total_std_lbs) %>% 
  drop_na(total_weight_lbs)

weights_tidy
```

|      Creating a data frame with only notes and dates they were recorded. Similar method to tidying the weight_tidy data frame.

```{r notes_df}
notes_tidy = 
  read_excel(
    "./data/dogweights_07sept2020.xlsx", skip = 1) %>%
  janitor::clean_names() %>%
  select(date, x6) %>%
  mutate(
    date = as.numeric(date),
    date = as.Date(date, origin = "1899-12-30")) %>% 
  rename(notes = x6) %>% 
  drop_na(notes)

notes_tidy
```

|      Exporting the weights_tidy and notes_tidy data frames.

```{r export}
write_csv(weights_tidy, "./data/weights_df.csv")
write_csv(notes_tidy, "./data/notes_df.csv")
```

### Problem 2

|      Our weights_tidy data set is ordered by date and includes weight data in both pounds and ounces (and their standard deviations) for each dog by pet_name.Number of unique dates were isolated by creating a new data frame (n_dates) with duplicate dates eliminated then counting the number of rows.

```{r n_dates}
n_dates = 
  weights_tidy %>% 
  distinct(date)

n_dates
```

|      Number of unique dates is equal to **`r nrow(n_dates)`**

|      Constructed a summary table including mean weight, mean standard deviation, and number of observations for each dog. This was done by first grouping by pet name and finding the means for each dog without including any missing values. Summary table was produced using the 'kable' command from the knitr package.

```{r summary}
summary_table =
  weights_tidy %>% 
    group_by(pet_name) %>% 
    summarize(
      n_obs = n(),
      mean_weight_lbs = mean(total_weight_lbs, na.rm = TRUE),
      mean_std_lbs = mean(total_std_lbs, na.rm = TRUE))
```

**Summary Table**

`r knitr::kable(summary_table)`

### Problem 3

|      Constructing a two-panel plot with the left panel showing the weight distribution for each pet in a density plot, and the right panel showing the distribution of weights of each dog over time in a scatter plot.

```{r plots}
weight_dist_plot =
  weights_tidy %>% 
  ggplot(aes(x = total_weight_lbs, fill = pet_name)) +
  geom_density(alpha = .7, adjust = .7) + 
  labs(
    title = "Weight Distributions per Pet",
    x = "Weight (lbs)",
    y = "Density") +
  scale_x_continuous(
    breaks = c(8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21)) +
  facet_grid(pet_name ~ .)

weight_time_plot =
  weights_tidy %>% 
  ggplot(aes(x = date, y = total_weight_lbs, color = pet_name)) + 
  geom_point(alpha = .5) +
  geom_smooth(se = FALSE) +
  labs(
    title = "Weight Distributions over time",
    x = "Date (months)",
    y = "Weight (lbs)")

weight_dist_plot + weight_time_plot
```

|      A striking observation is that of how Gagne's weight was in constant decline until Gagne passed away in September of 2019. Raisin and Simone both experienced dips in their weight throughout the year 2019.
|      Weight distributions for Gagne and Simone were similar and focused around the 10.5 lbs value. While for Raisin, the weight distribution is 'wider' with a focus on weights ranging from 17 to 19 lbs. 
